use bajzel_lib::lexer::{Lexer, Token};
use pretty_assertions::assert_eq;
use std::fs::read_to_string;

#[test]
fn example1() {
    let input = read_to_string("./examples/example1.fuzl").unwrap();
    let output = Lexer::lex_tokens(input.as_str());
    let expected = vec![
        Token::Define,
        Token::UserIdent("repl_command"),
        Token::StringLiteral("REPL"),
        Token::As,
        Token::UserIdent("prefix"),
        Token::StringLiteral(":"),
        Token::As,
        Token::UserIdent("delim1"),
        Token::Type("u32"),
        Token::As,
        Token::UserIdent("payload_len"),
        Token::StringLiteral(","),
        Token::As,
        Token::UserIdent("delim2"),
        Token::Type("bytes"),
        Token::As,
        Token::UserIdent("payload"),
        Token::Type("ref"),
        Token::As,
        Token::UserIdent("mem_range"),
        Token::Where,
        Token::UserIdent("prefix"),
        Token::RightArrow,
        Token::UserIdent("NO_MUTATE"),
        Token::Comma,
        Token::UserIdent("delim1"),
        Token::RightArrow,
        Token::UserIdent("DELIM"),
        Token::UserIdent("NO_MUTATE"),
        Token::Comma,
        Token::UserIdent("payload_len"),
        Token::RightArrow,
        Token::UserIdent("RANGE"),
        Token::LeftParen,
        Token::IntegerLiteral(0),
        Token::IntegerLiteral(4096),
        Token::RightParen,
        Token::Comma,
        Token::UserIdent("delim2"),
        Token::RightArrow,
        Token::UserIdent("DELIM"),
        Token::Comma,
        Token::UserIdent("payload"),
        Token::RightArrow,
        Token::UserIdent("LEN"),
        Token::LeftParen,
        Token::UserIdent("payload_len"),
        Token::RightParen,
        Token::Comma,
        Token::UserIdent("mem_range"),
        Token::RightArrow,
        Token::UserIdent("REF"),
        Token::LeftParen,
        Token::UserIdent("int_pair"),
        Token::RightParen,
        Token::Define,
        Token::UserIdent("int_pair"),
        Token::Type("i32"),
        Token::As,
        Token::UserIdent("x1"),
        Token::StringLiteral(","),
        Token::As,
        Token::UserIdent("delim"),
        Token::Type("i32"),
        Token::As,
        Token::UserIdent("x2"),
        Token::Where,
        Token::UserIdent("x1"),
        Token::RightArrow,
        Token::UserIdent("RANGE"),
        Token::LeftParen,
        Token::IntegerLiteral(0),
        Token::IntegerLiteral(15),
        Token::RightParen,
        Token::Comma,
        Token::UserIdent("x2"),
        Token::RightArrow,
        Token::UserIdent("RANGE"),
        Token::LeftParen,
        Token::IntegerLiteral(0),
        Token::IntegerLiteral(255),
        Token::RightParen,
        Token::Comma,
        Token::UserIdent("delim"),
        Token::RightArrow,
        Token::UserIdent("DELIM"),
        Token::Generate,
        Token::UserIdent("repl_command"),
        Token::With,
        Token::UserIdent("MIN"),
        Token::Assign,
        Token::IntegerLiteral(5),
        Token::UserIdent("MAX"),
        Token::Assign,
        Token::IntegerLiteral(4096),
        Token::UserIdent("TERM"),
        Token::Assign,
        Token::ReservedIdent("null"),
        Token::Eof,
    ];

    assert_eq!(output, Ok(expected));
}

#[test]
fn bitmap() {
    let input = read_to_string("./examples/bitmap.fuzl").unwrap();
    let output = Lexer::lex_tokens(input.as_str());
    let expected = vec![
        Token::Define,
        Token::UserIdent("bmp_header"),
        Token::Bytes(vec![66, 77]),
        Token::As,
        Token::UserIdent("magic"),
        Token::Type("le_u16"),
        Token::As,
        Token::UserIdent("size"),
        Token::TypeArray("bytes", 2),
        Token::TypeArray("bytes", 2),
        Token::Type("le_u16"),
        Token::As,
        Token::UserIdent("offset"),
        Token::Eof,
    ];

    assert_eq!(output, Ok(expected));
}
